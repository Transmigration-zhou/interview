## 消息队列

### 消息队列的两种模式

- **点对点模式**（一对一，消费者主动拉取数据，消息收到后消息清除）
  - 生产者生产消息发送到Queue中，然后消费者从Queue中取出并且消费消息。消息被消费以后，queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。

- **发布订阅模式**（一对多，消费者消费数据之后不会清除消息）
  - 生产者将消息**发布**到 topic 中，同时有多个消费者**订阅**该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。
  - Kafka 采取拉取模型，由自己控制消费速度，以及消费的进度，消费者可以按照任意的偏移量进行消费。

### 为什么使用消息队列

主要有三个核心场景：**解耦**、**异步**、**削峰**。

#### 解耦

在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。

![mq-1](https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-1.png)

通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。

一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的。

![mq-2](https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-2.png)

#### 异步

![mq-3](https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-3.png)

A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms。

![mq-4](https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-4.png)

如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms。

#### 削峰

在高峰期每秒并发请求数量会到 5k+ 条。一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。

![mq-6](https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-6.png)

只要高峰期一过，A 系统就会快速将积压的消息给解决掉。

### 消息队列有什么缺点

- 系统可用性降低
  - 系统引入的外部依赖越多，越容易挂掉
- 系统复杂度提高
  - 要保证消息没有重复消费、处理消息丢失的情况、保证消息传递的顺序性
- 一致性问题
  - A 系统处理完了直接返回成功了，但是BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，导致数据就不一致



## Kafka

### Kafka 的基本架构

![img](http://img.godjiyi.cn/csdnblogkafka-arc.jpg)

Kafka 集群由多个 broker 组成，每个 broker 是一个节点。你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。

#### Topic（主题）

Topic 是一个存储消息的逻辑概念，可以认为是一个消息集合。每条消息发送到 Kafka 集群的消息都有一个类别，这个类别就是 Topic。

不同的生产者将不同的业务消息分发到不同的 **topic** 上，这样消费者就可以根据 **topic** 进行对应的业务消息消费了。

每个 Topic 可以有多个生产者向它发送消息，也可以有多个消费者去消费其中的消息。

#### Broker

- 一个 broker 就是一个 kafka 节点，多个 broker 构成一个 kafka 集群。

#### Partition（分区）

- 一个**主题**分成多个**分区**，一个**分区**只属于单个**主题**，，很多时候也会把分区称为主题分区（Topic-Partition），每个 partition 是一个有序的消息序列
- 同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）
- 多个 **producer** 生产消息可以并行入队，多个 **consumer** 可并行消费
- 同一个 **partition** 里保证消息有序，不同 **partition** 则不能完全保证有序
  - offset 是消息在分区中的唯一标识，Kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区，也就是说，Kafka 保证的是分区有序而不是主题有序。

> 选择分区的原则
>
> 1. 指定了 partition
> 2. 没有指定 partition 但设置了 key，则根据 key 的值 hash 出一个 partition
> 3. 没有指定分区，没有设置 key，则轮询各分区发送，即每次取一小段时间的数据写入某个 partition，下一小段时间的数据写入下一个 partition

#### Replica

Replica（副本）指的是一个分区（Partition）的备份。

![img_7654f69f203c098f49c7054dc84fc1b9.png](https://yqfile.alicdn.com/img_7654f69f203c098f49c7054dc84fc1b9.png)

简单的replica分配示意图（圆角矩形代表replica）

这种分配保证了，任何一台机器挂掉，kafka集群依然有备份可用。

分为 **Leader**（主节点，1） 和 **Follower**（从节点，N）两种角色。

生产者发送数据的对象，以及消费者消费数据的对象都是 leader。

follower 实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader。

#### Consumer Group

消费者组就是消费者组成的一个组，消费者在向 Kafka 拉取（pull）数据的时候需要提供一个组名，这个名称就是消费者组名。两种消息模式都可以在消费者组中得到实现。

> consumer 采用 pull（拉）模式从 broker 中读取数据。
>
> push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。而 pull 模式则可以根据 consumer的消费能力以适当的速率消费消息。

1. **点对点/队列模式**：一个消息只能被一个消费者消费，我们只需要将这些消费者放在同一个消费者组里就可以了，这样消费者在同一个组中，那么 topic 中的一条消息只会向一个消费者组发送一次；
2. **发布-订阅模式**：一个消息可被多个消费者消费，这种情况，我们只需要将各个消费者放在各自单独的组中，各个组均订阅了此消息 topic 就可以了。

注意点：

- 一个消费组消费一个 **topic** 的全量数据；
- 组内消费者消费一个或多个 **partition** 数据，如果一个组里的消费者数量少于订阅的 topic 的 partition 数量，那么组中必有一个消费者要消费多个 partion 数据；
- 一个组里的消费者应小于等于 **topic** 的 **partition** 数量，这是因为一个 partition 最多只能与一个 consumer 连接，那么如果 partition 数量大于 consumer 数量，则必定有 consumer 是空闲的，因此尽量避免这种情况；

### Kafka 消息发送和消费流程

Kafka 有三次消息传递的过程

1. Producer 端发送消息给 Broker 端
2. Broker 将消息进行并持久化数据
3. Consumer 端从 Broker 将消息拉取并进行消费

#### 生产者往kafka发送数据的流程

![image-20231025120538386](https://gitee.com/Transmigration_zhou/pic/raw/master/image-20231025120538386.png)

1. 生产者从 Kafka 集群获取分区 leader 信息
2. 生产者将消息发送给 leader
3. leader 将消息写入本地磁盘
4. follower 从 leader 拉取消息数据
5. follower 将消息写入本地磁盘后向 leader 发送 ACK
6. leader 收到所有的 follower 的 ACK 之后向生产者发送 ACK

#### 消费者消费消息流程

1. Consumer 需要通过订阅关系获取到集群元数据, 找到相关 Topic 对应的 Leader 分区的数据，然后通过 Pull 模式主动的去 Kafka 集群中拉取消息。
2. 拉取到消息后进行业务逻辑处理，待处理完成后，会进行 ACK 确认，即提交 Offset 消费位移进度记录。
3. 最后 Offset 会被保存到 Kafka Broker 集群中的 consumer_offsets 这个 Topic 中，且每个 Consumer 保存自己的 Offset 进度。

### Kafka是如何实现高吞吐的

- 零拷贝技术
  - Kafka在读写数据时使用了零拷贝技术，即将数据直接从磁盘读入内核缓冲区，避免了一次次的内存拷贝和系统调用，提高了IO效率。
- 页缓存技术 + 磁盘顺序写
- ![在这里插入图片描述](https://img-blog.csdnimg.cn/2d2f44793aea40b3a2027538a175ebb0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAV2VuV3VfQm90aA==,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center)
- 分区分段
  - Kafka的message是按topic分类存储的，topic中的数据又是按照一个一个的partition即分区存储到不同broker节点。每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的。这也非常符合分布式系统分区分桶的设计思想。
- 批量发送和消费
  - Kafka支持批量发送和消费消息，生产者可以将多个消息批量发送到Kafka集群，消费者可以一次性从多个分区中拉取多个消息进行消费，减少了网络传输次数和磁盘IO次数。

### Kafka如何保证消息有序性

两种方案：

- 方案一：kafka topic 只设置一个 partition 分区
- 方案二：producer 将消息发送到指定同一个 partition 分区

方案一：kafka 默认保证同一个 partition 分区内的消息是有序的，则可以设置 topic 只使用一个分区，这样消息就是全局有序，缺点是只能被 consumer group 里的一个消费者消费，降低了性能，不适用高并发的情况。

方案二：既然 kafka 默认保证同一个 partition 分区内的消息是有序的，则 producer 可以在发送消息时可以指定需要保证顺序的几条消息发送到同一个分区，这样消费者消费时，消息就是有序。

![方案二](https://img2018.cnblogs.com/i-beta/727602/202001/727602-20200113155600857-1227819328.png)

**总结：每个分区内的消息是有序的，而消费者组确保每个分区只由一个消费者处理，从而保证了消费整体上的顺序性。**



### Kafka如何保证消息不丢失

使用一个消息队列，其实就分为三大块：**生产者、中间件、消费者**，所以要保证消息就是保证三个环节都不能丢失数据。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/J0g14CUwaZfW5jtMU7dzOUhL6avJSwsu2mjicVf2ZjCmpS93xWFUBk07GK7hqvIdMawwKV5YjXF69jnAPyuceKQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1&tp=webp)

- **消息生产阶段**：生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 （ MQ 中间件） 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。
- **消息存储阶段**：Kafka 在使用时是部署一个集群，生产者在发布消息时，队列中间件通常会写「多个节点」，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。
- **消息消费阶段**：消费者接收消息+消息处理之后，才回复 ack 的话，那么消息阶段的消息不会丢失。不能收到消息就回 ack，否则可能消息处理中途挂掉了，消息就丢失了。



### Kafka如何保证消息不重复消费

导致重复消费的原因可能出现在生产者，也可能出现在 MQ 或 消费者。

这里说的重复消费问题是指同一个数据被执行了两次，不单单指 MQ 中一条消息被消费了两次，也可能是 MQ 中存在两条一模一样的消费。

- 生产者：生产者可能会重复推送一条数据到 MQ 中，为什么会出现这种情况呢？也许是一个 Controller 接口被重复调用了 2 次，没有做接口幂等性导致的；也可能是推送消息到 MQ 时响应比较慢，生产者的重试机制导致再次推送了一次消息。
- MQ：在消费者消费完一条数据响应 ack 信号消费成功时，MQ 突然挂了，导致 MQ 以为消费者还未消费该条数据，MQ 恢复后再次推送了该条消息，导致了重复消费。
- 消费者：消费者已经消费完了一条消息，正准备但是还未给 MQ 发送 ack 信号时，此时消费者挂了，服务重启后 MQ 以为消费者还没有消费该消息，再次推送了该条消息。

消费者怎么解决重复消费问题呢？这里提供两种方法：

- 状态判断法：消费者消费数据后把消费数据记录在 redis 中，下次消费时先到 redis 中查看是否存在该消息，存在则表示消息已经消费过，直接丢弃消息。
- 业务判断法：通常数据消费后都需要插入到数据库中，使用数据库的唯一性约束防止重复消费。每次消费直接尝试插入数据，如果提示唯一性字段重复，则直接丢失消息。一般都是通过这个业务判断的方法就可以简单高效地避免消息的重复处理了。

### 解决kafka消费积压问题

消费积压就是产生的数据堆积没有实时消费数据。比如一分钟消费1000条，但是每分钟会产生2000条消息，就会存在1000条的积压。

积压造成的原因，基本都可以定位为消费能力不足。

对Kafka的消费主要是三部分向Kafka拿数据，对拿到的数据进行计算和对计算后的数据进行输出。

向Kafka拿数据很难成为瓶颈，因为Kafka磁盘顺序读写，顺序读写的速度都是远大于随机读写的。

对拿到的数据进行计算主要是业务部分，看是否能优化时间复杂度。

将计算后的数据输出，通常写入目标数据库表，随着写入数据量的越来越多，排序消耗的时间理论上也会越来越长。

#### 解决方案

针对不同的问题，解决办法需要对症下药。

1、计算复杂度过高：需要优化计算逻辑

- 对计算逻辑进行优化，可能涉及到算法改进、减少不必要的计算步骤、降低时间复杂度等。
- 使用更高效的数据结构和算法，以提高计算效率。

2、计算过程中涉及到的高IO操作：需要将额外的数据源提前加载到内存中

- 将频繁的、高IO的数据源提前加载到内存中，减少对外部数据的实时读取次数。
- 使用缓存机制，避免重复读取相同的外部数据。

3、数据库写入端太慢

- 增加写入缓冲区的大小，以减少写入数据库的频次。
- 优化写入过程，将多次的频繁写入操作优化为批量写入，减少数据库事务的开销。
- 增加写入端的并行度，考虑将单机表优化为分布式表，以提高整体写入性能。

4、增加 Kafka Topic的 Partition 数量（提高消费端并行度，仅限于不涉及以上三个瓶颈时）

- 增加要处理的 Kafka Topic 的 Partition 数量，这样消费程序就能够以更大的并行度来处理数据。
- 每个 Partition 对应一个独立的消费者，从而提高整体消费能力。

### Kafka 分区的目的和作用

Kafka的分区是指将Kafka Topic中的消息分散到多个分区中。分区的主要目的是实现消息的并行处理，提高Kafka的吞吐量和性能。